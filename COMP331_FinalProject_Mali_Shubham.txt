COMP331 Final Project – Data Mining Quality & Bias Analysis
Student: Shubham Mali

1. INTRODUCTION

This project analyzes the Adult Income dataset from the UCI Machine Learning Repository, which contains demographic, employment, and income information for over 30,000 individuals. The goal is to evaluate how data quality issues such as missing values, sampling bias, and fairness concerns can affect the performance and ethical integrity of data mining models. Since this dataset is commonly used to build income-prediction classifiers, data quality is especially important because biased or incomplete training data can produce discriminatory or misleading outcomes.

The analysis focuses on four key data quality dimensions relevant to data mining: completeness, sampling bias, labeling quality, and fairness across gender and race. All computations were conducted in R, including missing-value detection, class-imbalance measurement, and statistical comparisons across demographic groups. This work applies key concepts from Weeks 10–11, including data preparation in the CRISP-DM framework, sources of bias in machine learning, and the importance of fairness in model evaluation.

GitHub Repository: https://github.com/Shubham247-coder/COMP331-Final-Project

2. DATA QUALITY ANALYSIS

2.1 Missing Values and Completeness

Missing values are encoded as “?” in the Adult dataset. After cleaning, the variables with the most missingness were: workclass (5.64% missing), occupation (5.66% missing), and native_country (1.79% missing). All remaining variables had 0% missing values. These missing values reduce overall completeness and may disproportionately affect individuals whose employment categories are harder to classify. In the course material, data preparation is highlighted as consuming about 80% of the effort in data mining projects, underscoring how crucial proper handling of missing data is for reliable models. Dropping these records entirely would remove a non-trivial portion of the dataset and may introduce new bias.

2.2 Sampling Bias and Class Imbalance

A central quality issue in the dataset is its strong class imbalance: 75.92% of individuals have income <=50K, while only 24.08% have income >50K. This imbalance creates sampling bias, causing classifiers to favor the majority class and potentially inflate accuracy while misclassifying higher-income individuals. This problem is consistent with the course discussion of sampling bias as a major threat to model reliability.

Additionally, the dataset contains more male than female records, and some racial groups (such as Black, Amer-Indian-Eskimo, and Other) are underrepresented compared to White and Asian-Pacific Islander individuals. This imbalance can reduce the representativeness of mining models for minority groups.

2.3 Labeling Quality and Fairness Issues

Although the income label is encoded consistently (<=50K, >50K), its design raises validity concerns, as it collapses income into a simplistic binary category. More importantly, demographic fairness analysis reveals substantial inequalities. By gender, only 10.95% of females are in the >50K class, compared to 30.57% of males, meaning a male is nearly three times more likely to appear in the higher-income category. By race, 25.59% of White individuals and 26.56% of Asian-Pac-Islander individuals earn >50K, compared to 12.39% of Black individuals, 11.58% of Amer-Indian-Eskimo individuals, and 9.23% of Other races. These large differences show strong racial and gender disparities embedded in the labels.

The course’s ethics and fairness module emphasizes that biased data can lead to biased models and real-world harm if such models are used in areas like hiring or credit decisions. Without mitigation, any classifier trained on this dataset may reinforce these inequalities.

3. RECOMMENDATIONS

1. Structured Imputation for Missing Values
Replace “?” with proper missing values in R and use mode imputation or an “Unknown” category, along with indicator variables for imputed fields. This preserves completeness while avoiding accidental exclusion of specific demographic groups.

2. Address Class Imbalance and Sampling Bias
Use stratified sampling, oversampling of the >50K group, or class-weighting during model training. These techniques align with the CRISP-DM emphasis on careful data preparation before modeling and help classifiers better learn from the minority class.

3. Evaluate Fairness Across Demographic Groups
Alongside accuracy, compute fairness metrics such as group-specific recall, true positive rates, and false negative rates across gender and race. This reflects the course’s guidance on fairness-aware model evaluation and helps identify where models treat groups differently.

4. Improve Label Quality
Where possible, replace the binary income threshold with a more granular measure (for example, multiple income brackets). This enhances validity and reduces information loss about economic differences within each class.

5. Maintain a Transparent Data Quality Report
Document cleaning steps, imputation decisions, and resampling strategies in a simple data quality log. This supports ethical accountability and transparency in line with the course’s discussion of responsible data mining.

4. CONCLUSION

This project demonstrates that the Adult Income dataset contains significant data quality concerns related to missing values, sampling bias, labeling validity, and fairness across gender and race. These issues can strongly influence the accuracy and ethical reliability of data mining models. By applying the concepts from Weeks 10–11—particularly data preparation, bias detection, and fairness evaluation—it becomes clear that data quality assessment is a foundational requirement before building predictive models. Ensuring completeness, mitigating bias, and evaluating fairness are necessary steps for producing trustworthy and responsible data mining results.
